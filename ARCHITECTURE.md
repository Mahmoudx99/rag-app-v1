# ğŸ—ï¸ RAG Knowledge Base - Architecture Documentation

## System Overview

The RAG Knowledge Base is a microservices-based application designed for semantic search and AI-powered chat across PDF documents. It uses modern containerization, vector databases, machine learning for efficient document retrieval, and LLM integration for intelligent question answering.

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           User Browser                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ HTTP
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Frontend Container (Nginx + React)             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  â€¢ React 18 SPA                                          â”‚     â”‚
â”‚  â”‚  â€¢ Drag & Drop Upload                                    â”‚     â”‚
â”‚  â”‚  â€¢ Hybrid Search Interface (Semantic + Keyword)          â”‚     â”‚
â”‚  â”‚  â€¢ AI Chat Interface with Context Viewer                 â”‚     â”‚
â”‚  â”‚  â€¢ Document Management UI                                â”‚     â”‚
â”‚  â”‚  â€¢ Advanced Search Filters                               â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ REST API (Port 8000)
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Backend Container (FastAPI + Python)                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ PDF          â”‚ Embedding    â”‚ Hybrid       â”‚ Chat         â”‚   â”‚
â”‚  â”‚ Processor    â”‚ Service      â”‚ Search Svc   â”‚ Service      â”‚   â”‚
â”‚  â”‚              â”‚              â”‚              â”‚              â”‚   â”‚
â”‚  â”‚ â€¢ Plain Mode â”‚ â€¢ Sentence   â”‚ â€¢ BM25       â”‚ â€¢ LLM        â”‚   â”‚
â”‚  â”‚ â€¢ Paragraph  â”‚   Transform  â”‚ â€¢ Semantic   â”‚   Orchestr.  â”‚   â”‚
â”‚  â”‚   Chunking   â”‚ â€¢ Batch      â”‚ â€¢ RRF Fusion â”‚ â€¢ Context    â”‚   â”‚
â”‚  â”‚ â€¢ Metadata
   â”‚   Embed
   |could be saved 
   |in redis      â”‚ â€¢ Boolean    â”‚   Injection  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                   â”‚
â”‚  API Routes:                                                      â”‚
â”‚  â€¢ POST   /api/v1/documents/upload                                â”‚
â”‚  â€¢ POST   /api/v1/documents/process-file  â† File Watcher Events  â”‚
â”‚  â€¢ GET    /api/v1/documents/                                      â”‚
â”‚  â€¢ DELETE /api/v1/documents/{id}                                  â”‚
â”‚  â€¢ POST   /api/v1/search/                                         â”‚
â”‚  â€¢ POST   /api/v1/chat/                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                â”‚             â”‚               â”‚        â†‘
       â”‚ SQLAlchemy     â”‚ File System â”‚ ChromaDB      â”‚        â”‚ HTTP Event
       â†“                â†“             â†“               â†“        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PostgreSQL   â”‚ â”‚ File Storageâ”‚ â”‚  ChromaDB   â”‚ â”‚ LLM Service     â”‚
â”‚              â”‚ â”‚             â”‚ â”‚             â”‚ â”‚ Container       â”‚
â”‚ â€¢ Documents  â”‚ â”‚ â€¢ /data/    â”‚ â”‚ â€¢ Vectors   â”‚ â”‚                 â”‚
â”‚   Metadata   â”‚ â”‚   uploads/  â”‚ â”‚ â€¢ Embeddingsâ”‚ â”‚ â€¢ Gemini 2.0    â”‚
â”‚ â€¢ Status     â”‚ â”‚ â€¢ /data/    â”‚ â”‚ â€¢ Cosine Simâ”‚ â”‚ â€¢ Tool Calling  â”‚
â”‚ â€¢ Chunk IDs  â”‚ â”‚   watch/    â”‚ â”‚ â€¢ Persistenceâ”‚ â”‚ â€¢ Model Agnosticâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”‚ File System Events
                        â†“
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚   File Watcher Service (Python)    â”‚
               â”‚                                     â”‚
               â”‚  â€¢ Watchdog (filesystem monitor)   â”‚
               â”‚  â€¢ Event-driven architecture       â”‚
               â”‚  â€¢ GCP-ready design (Pub/Sub)      â”‚
               â”‚  â€¢ Idempotent processing           â”‚
               â”‚  â€¢ Automatic retry logic           â”‚
               â”‚                                     â”‚
               â”‚  GCP Migration Path:               â”‚
               â”‚  â†’ Cloud Storage Triggers          â”‚
               â”‚  â†’ Cloud Functions                 â”‚
               â”‚  â†’ Pub/Sub messaging               â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Component Details

### 1. Frontend (React + Nginx)

**Technology Stack:**
- React 18
- Axios for API calls
- React Dropzone for file uploads
- React Toastify for notifications
- Nginx for production serving

**Key Features:**
- Responsive, modern UI
- Tab-based navigation (Search/Chat/Documents)
- Real-time upload progress
- Drag & drop file upload
- Hybrid search with mode selection (Semantic/Keyword/Hybrid)
- Advanced search filters (date, document, boolean operators)
- AI Chat interface with context viewer
- Chunk selection for RAG context
- Document management (view/delete)
- Statistics dashboard

**Files:**
```
frontend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ DocumentList.js       # Document grid view
â”‚   â”‚   â”œâ”€â”€ SearchBar.js          # Search input with mode selector
â”‚   â”‚   â”œâ”€â”€ SearchResults.js      # Results with chunk selection
â”‚   â”‚   â”œâ”€â”€ AdvancedSearch.js     # Filter panel
â”‚   â”‚   â”œâ”€â”€ ChatInterface.js      # AI chat UI
â”‚   â”‚   â”œâ”€â”€ UploadArea.js         # Drag & drop upload
â”‚   â”‚   â””â”€â”€ PDFViewer.js          # PDF preview modal
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ api.js                # API client (documents, search, chat)
â”‚   â””â”€â”€ App.js                    # Main component
â””â”€â”€ Dockerfile                    # Multi-stage build
```

### 2. Backend (FastAPI)

**Technology Stack:**
- FastAPI (async Python web framework)
- SQLAlchemy (ORM)
- Pydantic (data validation)
- pdfminer.six (PDF processing)
- sentence-transformers (embeddings)
- ChromaDB (vector storage)
- rank-bm25 (keyword search)
- httpx (async HTTP client for LLM service)

**Architecture Pattern:**
- **Layered Architecture**
  - API Layer (routes)
  - Service Layer (business logic)
  - Data Layer (models, database)

**Key Services:**

#### PDF Processor Service
```python
class PDFProcessor:
    - extract_metadata()  # Extract PDF info
    - extract_text()      # Plain text extraction
    - chunk_text()        # Paragraph-based chunking
    - process_pdf()       # Complete workflow
```

**Chunking Algorithm:**
1. Extract paragraphs (split on `\n\n`)
2. Check paragraph length
3. If < chunk_size: Keep as single chunk
4. If > chunk_size: Split by sentences
5. Apply overlap between chunks
6. Generate unique chunk IDs (hash-based)

#### Embedding Service
```python
class EmbeddingService:
    - load_model()           # Load sentence-transformers
    - generate_embeddings()  # Batch processing
    - generate_embedding()   # Single text
```

**Model Details:**
- Default: all-MiniLM-L6-v2 (downloaded at build time)
- Dimensions: 384
- Normalized embeddings (unit length)
- Batch size: 32 (configurable)
- Offline mode enabled (no runtime downloads)

#### Hybrid Search Service
```python
class HybridSearchService:
    - hybrid_search()        # Combined search
    - _semantic_search()     # Vector similarity
    - _keyword_search()      # BM25 ranking
    - _reciprocal_rank_fusion()  # Score combination
```

**Search Modes:**
- **Hybrid**: Combines semantic + keyword with RRF
- **Semantic**: Pure vector similarity search
- **Keyword**: BM25 text matching

**Advanced Filters:**
- Date range filtering
- Document ID filtering
- Boolean operators (AND/NOT/OR)

#### Chat Service
```python
class ChatService:
    - chat()                 # Main orchestration
    - _call_llm_generate()   # Direct LLM call
    - _chat_with_tools()     # Tool-based search
    - get_history()          # Conversation history
    - clear_history()        # Reset conversation
```

**Features:**
- Conversation history management
- Context injection from selected chunks
- Tool calling for AI-driven search
- Async HTTP communication with LLM service

#### Vector Store Service
```python
class VectorStore:
    - add_documents()     # Bulk insert
    - search()            # Similarity search
    - delete_by_ids()     # Remove chunks
    - delete_by_source()  # Remove by document
```

**ChromaDB Configuration:**
- Distance metric: Cosine similarity
- Index: HNSW (approximate nearest neighbors)
- Persistent storage: DuckDB + Parquet

**Files:**
```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/routes/
â”‚   â”‚   â”œâ”€â”€ documents.py      # Document CRUD
â”‚   â”‚   â”œâ”€â”€ search.py         # Hybrid search endpoint
â”‚   â”‚   â””â”€â”€ chat.py           # Chat orchestration
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py         # Settings
â”‚   â”‚   â””â”€â”€ database.py       # DB connection
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ document.py       # SQLAlchemy models
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ pdf_processor.py
â”‚   â”‚   â”œâ”€â”€ embedding_service.py
â”‚   â”‚   â”œâ”€â”€ vector_store.py
â”‚   â”‚   â”œâ”€â”€ hybrid_search.py   # BM25 + Semantic
â”‚   â”‚   â””â”€â”€ chat_service.py    # LLM orchestration
â”‚   â””â”€â”€ main.py              # FastAPI app
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt          # Core dependencies
â””â”€â”€ requirements-chat.txt     # LLM integration deps
```

### 3. File Watcher Service (Event-Driven Processing)

**Purpose:** Automatic PDF processing by monitoring a folder

**Technology Stack:**
- Python 3.11
- watchdog (filesystem monitoring)
- httpx (async HTTP client)
- pydantic-settings (configuration)
- python-json-logger (structured logging)

**Architecture Pattern:**
- **Event-Driven** - Decoupled file detection from processing
- **GCP-Ready** - Designed to map directly to Cloud Storage + Pub/Sub

**Key Components:**

#### Watcher Service
```python
class FolderWatcher:
    - start()                    # Begin monitoring
    - _process_existing_files()  # Handle files on startup
    - _stability_check_loop()    # Ensure uploads complete
    - _create_file_event()       # Generate event payload
```

#### Event Publisher (Abstraction for Pub/Sub)
```python
class EventPublisher(ABC):
    - publish()                  # Send event to backend
    - close()                    # Cleanup

class DirectHTTPPublisher(EventPublisher):
    - publish()                  # HTTP POST to backend
    # GCP: Replace with PubSubEventPublisher
```

#### File Tracker (Idempotency)
```python
class FileTracker:
    - is_processed()     # Check if already processed
    - mark_pending()     # Start tracking
    - mark_success()     # Completed successfully
    - mark_failed()      # Track failures
```

**Event Schema (GCS-Compatible):**
```python
@dataclass
class FileEvent:
    event_type: str      # "OBJECT_FINALIZE" (GCS standard)
    file_path: str       # Full path to file
    file_name: str       # Filename only
    file_size: int       # File size in bytes
    bucket: str          # Watch folder (maps to GCS bucket)
    timestamp: str       # ISO timestamp
    event_id: str        # Unique event ID
```

**Features:**
- Automatic folder monitoring
- File stability detection (ensures upload complete)
- Idempotent processing (no duplicates)
- Retry logic for failed processing
- Structured JSON logging (Cloud Logging ready)
- Graceful shutdown handling

**Files:**
```
file_watcher_service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # Service entry point
â”‚   â”œâ”€â”€ config.py            # Configuration (env vars)
â”‚   â”œâ”€â”€ watcher.py           # Filesystem monitoring
â”‚   â”œâ”€â”€ event_publisher.py   # Event publishing abstraction
â”‚   â””â”€â”€ file_tracker.py      # Deduplication tracker
â”œâ”€â”€ Dockerfile
â””â”€â”€ requirements.txt
```

**Configuration (Environment Variables):**
```bash
WATCHER_WATCH_FOLDER=/data/watch
WATCHER_BACKEND_URL=http://backend:8000
WATCHER_FILE_STABILITY_THRESHOLD=5.0
WATCHER_MAX_RETRIES=3
WATCHER_PROCESS_EXISTING_ON_STARTUP=true
```

### 4. LLM Service (Gemini)

**Purpose:** Model-agnostic LLM integration for AI chat

**Technology Stack:**
- FastAPI
- Google Generative AI (Gemini)
- Abstract provider pattern

**Architecture:**
```python
# Factory pattern for model swapping
class BaseLLMProvider:
    - generate()              # Standard generation
    - generate_stream()       # Streaming response
    - generate_with_tools()   # Function calling
    - health_check()          # Service health

class GeminiProvider(BaseLLMProvider):
    - Gemini 2.0 Flash model
    - Safety settings configured
    - Tool/function calling support
```

**Features:**
- Model-agnostic design (easy to swap providers)
- Function/tool calling for autonomous search
- Streaming support
- Conversation history handling
- Context injection

**Files:**
```
llm_service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”œâ”€â”€ base.py           # Abstract base class
â”‚   â”‚   â”œâ”€â”€ gemini.py         # Gemini implementation
â”‚   â”‚   â””â”€â”€ factory.py        # Provider factory
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ chat.py           # API endpoints
â”‚   â”œâ”€â”€ config.py             # Settings
â”‚   â””â”€â”€ main.py               # FastAPI app
â”œâ”€â”€ Dockerfile
â””â”€â”€ requirements.txt
```

**API Endpoints:**
- `POST /api/v1/generate` - Standard generation
- `POST /api/v1/generate/stream` - Streaming
- `POST /api/v1/generate/with-tools` - Tool calling
- `GET /api/v1/health` - Service health

### 4. PostgreSQL

**Purpose:** Metadata storage and document tracking

**Schema:**
```sql
CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    filename VARCHAR(255) NOT NULL,
    original_filename VARCHAR(255) NOT NULL,
    file_path VARCHAR(512) NOT NULL,
    file_size INTEGER NOT NULL,
    title VARCHAR(512),
    author VARCHAR(255),
    num_pages INTEGER,
    num_chunks INTEGER DEFAULT 0,
    chunk_ids JSON,
    uploaded_at TIMESTAMP DEFAULT NOW(),
    processed_at TIMESTAMP,
    status VARCHAR(50) DEFAULT 'pending',
    error_message TEXT
);
```

**Why PostgreSQL?**
- ACID compliance
- JSON support for chunk_ids
- Reliable metadata storage
- Easy backups
- Well-supported

### 5. ChromaDB

**Purpose:** Vector embeddings storage and similarity search

**Data Structure:**
```python
{
    "id": "chunk_abc123_0001_xyz789",
    "embedding": [0.123, -0.456, ...],  # 384 dims
    "document": "text content",
    "metadata": {
        "document_id": 1,
        "document_filename": "file.pdf",
        "source": "file.pdf",
        "chunk_index": 0,
        "char_count": 876,
        "word_count": 120
    }
}
```

**Why ChromaDB?**
- Simple Python API
- Built-in persistence
- Fast similarity search
- Low resource requirements
- Perfect for RAG applications

## Data Flow

### Upload Workflow

```
1. User uploads PDF
   â†“
2. Frontend â†’ POST /api/v1/documents/upload
   â†“
3. Backend saves file to /data/uploads/
   â†“
4. Create database record (status: processing)
   â†“
5. PDFProcessor.process_pdf()
   â”œâ”€â†’ extract_metadata() â†’ Get title, author, pages
   â”œâ”€â†’ extract_text() â†’ Extract plain text
   â””â”€â†’ chunk_text() â†’ Create paragraphs
   â†“
6. EmbeddingService.generate_embeddings()
   â””â”€â†’ Batch process all chunks
   â†“
7. VectorStore.add_documents()
   â””â”€â†’ Store in ChromaDB
   â†“
8. Update database record
   â”œâ”€â†’ status: completed
   â”œâ”€â†’ num_chunks: X
   â””â”€â†’ chunk_ids: [...]
   â†“
9. Return success to frontend
```

### Search Workflow

```
1. User enters query + selects mode (hybrid/semantic/keyword)
   â†“
2. Frontend â†’ POST /api/v1/search/
   â†“
3. Backend receives query + filters
   â†“
4. HybridSearchService.hybrid_search()
   â”œâ”€â†’ If hybrid: Run both searches
   â”‚   â”œâ”€â†’ Semantic: Generate embedding, ChromaDB search
   â”‚   â””â”€â†’ Keyword: BM25 ranking
   â”œâ”€â†’ If semantic: Only vector search
   â””â”€â†’ If keyword: Only BM25 search
   â†“
5. Apply advanced filters
   â”œâ”€â†’ Document ID filter
   â”œâ”€â†’ Date range filter
   â””â”€â†’ Boolean operators (AND/NOT/OR)
   â†“
6. Reciprocal Rank Fusion (for hybrid)
   â””â”€â†’ Combine scores with weighted RRF
   â†“
7. Format results with metadata
   â†“
8. Return to frontend
   â†“
9. Display ranked results with scores
```

### Chat Workflow

```
1. User sends message (with optional context chunks)
   â†“
2. Frontend â†’ POST /api/v1/chat/
   â†“
3. Backend ChatService orchestrates
   â†“
4. If "Allow AI to search" enabled:
   â”œâ”€â†’ Send to LLM with search tool definition
   â”œâ”€â†’ LLM decides to search (or not)
   â”œâ”€â†’ If search requested:
   â”‚   â”œâ”€â†’ Execute HybridSearchService.hybrid_search()
   â”‚   â”œâ”€â†’ Get relevant chunks
   â”‚   â””â”€â†’ Re-send to LLM with context
   â””â”€â†’ LLM generates final response
   â†“
5. If context chunks provided:
   â”œâ”€â†’ Inject chunks as context
   â””â”€â†’ LLM generates response
   â†“
6. Update conversation history
   â†“
7. Return response with sources
   â†“
8. Frontend displays message + context viewer
```

### Delete Workflow

```
1. User clicks delete
   â†“
2. Frontend â†’ DELETE /api/v1/documents/{id}
   â†“
3. Backend retrieves document record
   â†“
4. VectorStore.delete_by_ids(chunk_ids)
   â””â”€â†’ Remove from ChromaDB
   â†“
5. Delete PDF file from /data/uploads/
   â†“
6. Delete database record
   â†“
7. Return success
```

### File Watcher Workflow (Automated Processing)

```
1. User/System drops PDF into /data/watch/ folder
   â†“
2. Watchdog detects file creation event
   â†“
3. Wait for file stability (no modifications for 5s)
   â””â”€â†’ Ensures upload is complete
   â†“
4. Check if file already processed (idempotency)
   â†“
5. Create FileEvent with GCS-compatible schema:
   {
     event_type: "OBJECT_FINALIZE",
     file_path: "/data/watch/document.pdf",
     file_name: "document.pdf",
     bucket: "/data/watch",
     event_id: "uuid-here"
   }
   â†“
6. Publish event â†’ Backend API
   POST /api/v1/documents/process-file
   â†“
7. Backend processes PDF (same as upload):
   â”œâ”€â†’ Extract text & metadata
   â”œâ”€â†’ Chunk document
   â”œâ”€â†’ Generate embeddings
   â””â”€â†’ Store in ChromaDB
   â†“
8. File tracker marks as processed
   â†“
9. Document available in search & chat
```

**GCP Migration of This Workflow:**
```
1. User uploads PDF to GCS bucket
   â†“
2. Cloud Storage sends OBJECT_FINALIZE event to Pub/Sub
   â†“
3. Cloud Function receives Pub/Sub message
   â†“
4. Cloud Function calls Cloud Run backend
   POST /api/v1/documents/process-file
   â†“
5. Backend downloads from GCS, processes, stores
   â†“
6. Document available in search & chat
```

## Network Communication

```
Docker Network: rag-network
Type: Bridge

Container Communication:
- frontend:80 â†’ backend:8000 (HTTP API)
- backend â†’ postgres:5432 (PostgreSQL)
- backend â†’ chromadb (Python client, local)
- backend â†’ llm:8001 (HTTP API for LLM service)
- file_watcher â†’ backend:8000 (Event notifications)

External Access:
- localhost:3000 â†’ frontend:80
- localhost:8000 â†’ backend:8000
- localhost:8002 â†’ llm:8001 (LLM service)
- localhost:5432 â†’ postgres:5432 (optional)
```

## Storage Strategy

### Volumes

```yaml
volumes:
  - ./data/uploads:/data/uploads       # PDF files (UI uploads)
  - ./data/watch:/data/watch           # PDF files (auto-processing)
  - ./data/processed:/data/processed   # File tracking data
  - ./data/chromadb:/data/chromadb     # Vector DB
  - ./data/postgres:/var/lib/postgresql/data
```

### Data Persistence

| Data Type | Location | Backup Strategy |
|-----------|----------|----------------|
| PDF Files (UI) | /data/uploads | File system backup |
| PDF Files (Auto) | /data/watch | File system backup |
| File Tracker | /data/processed | JSON file backup |
| Embeddings | /data/chromadb | Directory backup |
| Metadata | /data/postgres | pg_dump |

## Security Considerations

### Current Implementation

- âœ… Non-root Docker users
- âœ… CORS configuration
- âœ… File type validation
- âœ… File size limits
- âœ… SQL injection protection (SQLAlchemy)

### Production Recommendations

- ğŸ”’ Add authentication (JWT)
- ğŸ”’ Enable HTTPS
- ğŸ”’ Rate limiting
- ğŸ”’ Input sanitization
- ğŸ”’ Secrets management
- ğŸ”’ Network isolation
- ğŸ”’ Regular updates

## Performance Characteristics

### Bottlenecks

1. **PDF Processing**: I/O bound (disk read)
2. **Embedding Generation**: CPU bound
3. **Vector Search**: Memory + CPU bound

### Optimization Strategies

**Current:**
- Batch embedding generation (32 per batch)
- Persistent connections (connection pooling)
- Efficient chunking algorithm

**Future:**
- Add GPU support for embeddings
- Implement caching layer (Redis)
- Use async database queries
- Add task queue (Celery)
- Horizontal scaling

### Estimated Performance

| Operation | Time | Throughput |
|-----------|------|------------|
| Upload 10-page PDF | ~5s | - |
| Generate embeddings (100 chunks) | ~10s | 10 chunks/s |
| Search query | <100ms | 10+ QPS |
| Delete document | ~500ms | - |

## Scalability

### Horizontal Scaling Options

```
Current: Monolithic Backend
Future Options:
â”œâ”€â”€ Load Balancer
â”œâ”€â”€ Multiple Backend Instances
â”œâ”€â”€ Separate Worker Service
â”œâ”€â”€ Redis Task Queue
â””â”€â”€ Distributed ChromaDB
```

### Resource Requirements

**Minimum:**
- 2 CPU cores
- 4GB RAM
- 10GB disk

**Recommended:**
- 4+ CPU cores
- 8GB RAM
- 50GB SSD

**For 10,000 Documents:**
- 8+ CPU cores
- 16GB RAM
- 100GB SSD

## Monitoring & Observability

### Logs

```bash
# Application logs
docker-compose logs -f backend

# Database logs
docker-compose logs -f postgres

# All logs
docker-compose logs -f
```

### Metrics

Available via API:
- `/api/v1/documents/stats/overview`
  - Total documents
  - Total chunks
  - Vector store count

### Health Checks

- Frontend: `http://localhost:3000`
- Backend: `http://localhost:8000/health`
- Postgres: Built-in healthcheck

## Technology Choices

### Why These Technologies?

**FastAPI:**
- âœ… Fast (ASGI)
- âœ… Async support
- âœ… Auto-generated docs
- âœ… Type hints
- âœ… Easy to learn

**React:**
- âœ… Component-based
- âœ… Rich ecosystem
- âœ… Fast rendering
- âœ… Easy state management

**ChromaDB:**
- âœ… Purpose-built for embeddings
- âœ… Simple API
- âœ… No external dependencies
- âœ… Good performance

**PostgreSQL:**
- âœ… Reliable
- âœ… JSON support
- âœ… ACID compliant
- âœ… Well-documented

**Docker:**
- âœ… Consistent environments
- âœ… Easy deployment
- âœ… Service isolation
- âœ… Resource control

## Future Enhancements

### Planned Features

1. **Authentication & Authorization**
   - User accounts
   - Document permissions
   - API keys

2. **Additional LLM Providers**
   - OpenAI GPT-4
   - Anthropic Claude
   - Local models (Ollama)
   - Cost optimization

3. **Enhanced Chat Features**
   - Streaming responses
   - Chat history persistence
   - Custom system prompts
   - Multi-turn reasoning

4. **File Type Support**
   - DOCX, TXT, HTML
   - Image OCR
   - Audio transcription

5. **Analytics**
   - Usage statistics
   - Popular searches
   - Document insights
   - Token usage tracking

6. **Collaboration**
   - Shared knowledge bases
   - Team workspaces
   - Comments & annotations

7. **Performance**
   - GPU support for embeddings
   - Response caching
   - Async processing queue
   - Horizontal scaling

---

**Designed for**: Scalability, maintainability, and production readiness
**Built with**: Modern best practices and clean architecture principles
